# ML 5주차 정규과제

📌ML 정규과제는 매주 정해진 **유튜브 강의 영상을 통해 머신러닝 이론을 학습**한 후, 해당 내용을 바탕으로 **실습 문제를 풀어보며 이해도를 높이는 학습 방식**입니다. 

이번주는 아래의 **ML_5th_TIL**에 명시된 유튜브 강의를 먼저 수강해 주세요. 학습 중에는 주요 개념을 스스로 정리하고, 이해가 어려운 부분은 강의 자료나 추가 자료를 참고해 보완해주세요. 과제까지 다 작성한 이후에 Github를 과제 시트에 제출해주시면 됩니다.



**(수행 인증샷은 필수입니다.)** 

> 주어진 과제를 다 한 이후, 인증샷이나 따로 코드를 깃허브에 정리하여 제출해주세요.



## ML_5th_TIL

### 랜덤포레스트 모델

<br>



## 주차별 학습 (Study Schedule)

| 주차   | 공부 범위                              | 완료 여부 |
| ------ | -------------------------------------- | --------- |
| 1주차. | 선형 회귀 (Linear Regression) (1)      | ✅         |
| 2주차  | 선형 회귀 (Linear Regression) (2)      | ✅         |
| 3주차  | 로지스틱 회귀 (Logistic Regression)    | ✅         |
| 4주차  | 결정 트리 (Decision Tree)              | ✅         |
| 5주차  | 앙상블 : 랜덤 포레스트 (Random Forest) | ✅         |
| 6주차  | 주성분 분석 (PCA)                      | 🍽️         |
| 7주차  | K - 평균 군집화                        | 🍽️         |

<!-- 여기까진 그대로 둬 주세요-->



---

# 1️⃣ 개념 정리

## 01. 랜덤포레스트 모델

```
✅ 학습 목표 :
* 랜덤 포레스트(Random Forest)의 개념과 필요성을 이해할 수 있다.
* Bagging과 Random Subspace의 원리와 역할을 이해할 수 있다.
* 랜덤 포레스트의 Generalization Error 개념을 이해할 수 있다.
* Out-of-Bag(OOB) Error와 변수 중요도 평가 방법을 이해할 수 있다.
* 랜덤 포레스트 모델의 주요 하이퍼파라미터를 이해하고 설정할 수 있다. 
```

## 🌳 랜덤 포레스트(Random Forest) 모델 심층 정리


### 1. 랜덤 포레스트의 개념과 필요성 이해

#### 1.1. 단일 의사결정 나무의 한계 (필요성)

단일 의사결정 나무(Decision Tree) 모델은 다음과 같은 단점을 가짐.

* **오류 전파:** 계층적 구조의 특성상, 중간 단계에서 발생한 예측 오류가 다음 단계로 계속 전파되어 최종 결과에 큰 영향을 줌.
* **고분산(High Variance):** 학습 데이터의 작은 변동에도 최종 결과가 크게 달라지며, 적은 노이즈에도 쉽게 영향을 받아 예측 안정성이 낮음.
* **과적합(Overfitting):** 나무의 최종 노드 개수를 늘려(깊게 성장시켜) 훈련 데이터의 정확도를 0에 가깝게 만들 수 있지만, 이는 과적합(Overfitting, Low Bias & **Large Variance**)을 유발하여 테스트 데이터에 대한 예측 정확도를 장담할 수 없게 함.

#### 1.2. 랜덤 포레스트 개념 (앙상블 모델)

랜덤 포레스트는 이러한 단일 나무의 한계를 극복하기 위해 제안된 **앙상블(Ensemble) 모델** 중 하나임.

* **정의:** 여러 개의 개별 의사결정 나무(Base Model)를 구축하고, 이들의 예측 결과를 **다수결 법칙** (분류 문제) 또는 **평균** (예측/회귀 문제)을 이용하여 통합하여 최종 결과를 도출함으로써 예측 정확성과 안정성을 향상시키는 방법임.
* **앙상블의 조건:**
    * 개별 베이스 모델들은 **최대한 서로 독립적**이어야 함. (낮은 상관관계 확보)
    * 개별 베이스 모델들은 무작위 예측 (이진 분류 시 50%)을 수행하는 모델보다는 성능이 좋아야 함. (오류율이 0.5보다 낮아야 앙상블 효과 발생)

---

### 2. Bagging과 Random Subspace의 원리와 역할 이해

랜덤 포레스트의 핵심 아이디어는 앙상블의 핵심 조건인 **다양성(Diversity)**과 **랜덤성(Randomness)**을 확보하는 두 가지 기법, **Bagging**과 **Random Subspace**에 기반함.

#### 2.1. Bagging (Bootstrap Aggregating)

* **원리:** 여러 개의 **다양한** 훈련 데이터셋을 생성하고, 각 데이터셋으로 개별 트리를 구축한 후 결과를 통합함.
* **단계:**
    * **Bootstrap (부트스트랩핑):** 원래 데이터셋에서 **복원 추출(Sampling with Replacement)** 방식을 사용하여, 원래 데이터셋과 **동일한 개수**의 샘플을 여러 개 생성함. (이는 각 개별 트리가 서로 다른 데이터 분포를 학습하도록 유도함.)
    * **Aggregating (통합):** 각 부트스트랩 셋으로부터 생성된 개별 트리의 결과를 **다수결(Voting)** 또는 **평균(Averaging)** 방식으로 합쳐 최종 예측을 결정함.

#### 2.2. Random Subspace (랜덤 부분 공간)

* **원리:** 개별 트리를 구축하는 과정에서 **랜덤성**을 극대화하여 나무들의 독립성을 확보함.
* **단계:**
    * 일반적인 의사결정 나무는 노드를 분할할 때 모든 변수를 고려하여 최적의 분할 변수를 찾음.
    * 랜덤 포레스트는 분할할 때마다 **총 변수의 개수보다 적은 수($m$)의 변수를 임의로 선택**하고, 선택된 $m$개의 변수 내에서만 최적의 분할 기준을 찾음.
* **역할:** 이 기법은 개별 트리가 서로 다른 변수 조합에 집중하도록 강제함으로써, 설령 강력한 소수의 변수가 있더라도 모든 트리가 그 변수만을 사용하게 되는 현상(높은 상관관계)을 방지하여 트리들의 **독립성**을 높임.

---

### 3. 랜덤 포레스트의 Generalization Error 개념 이해

랜덤 포레스트 모델의 **일반화 오류(Generalization Error)**, 즉 테스트 데이터에서의 예측 오류는 주로 **개별 트리의 정확도($s$)**와 **트리들 간의 상관관계($\rho$)**에 의해 결정됨.

일반화 오류의 상한선(Upper Bound)은 대략 다음과 같은 관계를 가짐.

$$\text{Generalization Error} \propto \frac{\rho \cdot (1 - s^2)}{s^2}$$

* $\rho$: 개별 의사결정 나무들 간의 **평균 상관관계** ($\rho$가 낮을수록 좋음)
* $s$: 올바르게 예측한 트리와 잘못 예측한 트리 수의 차이 평균 (개별 트리의 **정확도**를 반영하며, $s$가 클수록 좋음)

**오류를 줄이는 방법:**

1.  **상관관계($\rho$) 최소화:** **Random Subspace** 기법을 통해 트리를 최대한 독립적으로 만들어 상관관계를 낮춤.
2.  **정확도($s$) 최대화:** 개별 의사결정 나무가 최소한 무작위 예측(0.5)보다는 좋은 성능을 내도록 함.

---

### 4. Out-of-Bag(OOB) Error와 변수 중요도 평가 방법 이해

랜덤 포레스트는 별도의 교차 검증(Cross-Validation) 없이도 **OOB (Out-of-Bag) 데이터**를 사용하여 모델의 성능을 평가하고 변수의 중요도를 측정할 수 있음.

#### 4.1. Out-of-Bag (OOB) Error

* **OOB 데이터:** 부트스트랩핑 과정에서 **특정 개별 트리의 훈련 데이터셋에 한 번도 선택되지 않은** 나머지 데이터(이론적으로 약 36.8%)를 의미함.
* **OOB Error 역할:** 각 트리는 자신을 훈련하는 데 사용되지 않은 OOB 데이터를 사용하여 성능을 평가받음. 이 OOB 에러들을 평균 내어 최종적인 **일반화 오류 추정치**로 활용함.

#### 4.2. 변수 중요도(Feature Importance) 평가

랜덤 포레스트는 변수 중요도를 결정하는 고유한 방법을 가짐 (선형 회귀처럼 통계적 유의성을 가정하지 않는 비모수적(Non-Parametric) 방식임).

1.  **기준선(Baseline) 설정:** 특정 개별 트리에 대해 OOB 데이터를 사용하여 **OOB Error (Baseline)**를 계산함.
2.  **변수 값 무작위 뒤섞기 (Permutation):** 중요도를 측정하고자 하는 특정 변수($X_i$)의 값들을 OOB 데이터 내에서 임의로 **뒤섞음(Shuffle)**. (이는 $X_i$와 목표 변수 간의 관계를 끊어버리는 효과를 가져옴.)
3.  **오류 재계산:** 뒤섞인 $X_i$ 값을 가진 OOB 데이터를 사용하여 **OOB Error (Permuted)**를 다시 계산함.
4.  **중요도 측정:** 두 에러 간의 차이 **(Permuted Error - Baseline Error)**를 구하고, 이를 모든 트리에서 평균 냄.
    * **차이가 클수록** ($X_i$가 뒤섞였을 때 에러가 크게 증가할수록) 해당 변수 $X_i$는 모델 예측에 **매우 중요한 역할**을 했다고 판단함.

---

### 5. 랜덤 포레스트 모델의 주요 하이퍼파라미터 설정

랜덤 포레스트 자체에는 알고리즘으로 결정되는 파라미터는 없으나, 사용자가 직접 설정해야 하는 **하이퍼파라미터**가 존재함.

| 하이퍼파라미터 | 설명 | 일반적인 가이드라인 (문헌 참고) |
| :--- | :--- | :--- |
| **트리 개수 ($T$)** | 앙상블을 구성할 개별 의사결정 나무(Base Model)의 총 개수. | 최소 2000개 이상이 권장되나, 문제와 데이터셋에 따라 100~수만 개까지 설정하며 **성능이 안정화되는 지점**을 찾음. |
| **무작위 선택 변수 수 ($m$)** | 노드를 분할할 때 무작위로 선택할 변수($m$)의 개수. (**Random Subspace**) | **분류 문제 (Classification):** $\sqrt{\text{총 변수 수 (P)}}$ |
| | | **예측 문제 (Regression):** $P/3$ |

*위 가이드라인은 일반적인 시작점일 뿐이며, 최적의 하이퍼파라미터는 항상 실제 데이터를 기반으로 경험적 튜닝(Try and Error)을 통해 결정해야 함.*



<br>
<br>

---

# 2️⃣ 과제

> **4주차에 진행했던 와인 품질 데이터셋에 대해 랜덤 포레스트 모델을 적용해봅시다. `feature_importances`속성을 추출하여 어떤 변수들이 와인 품질 예측에 가장 중요한 역할을 하는지 시각화(막대 그래프)하고, 이번에는 상위 3개의 변수에 대해 설명하는 주피터 노트북을 작성해주세요.**



~~~
과제 가이드
1. 모델 학습
- 4주차에 사용한 와인 품질 데이터셋 재활용
- from sklearn.ensemble import RandomForestClassifier
- model.fit(X_train, y_train)으로 학습을 한다. 
- feature_importance 를 분석하여, 어떤 변수가 예측에 중요한 역할을 하는지 해석한다. 

* 힌트
- feature_importance란.? : 랜덤포레스트는 어떤 변수가 분할 시 예측 성능에 향상에 기여했는지를 평가한다.
- 즉 값이 클수록 중요하다. 
~~~



<br>

### 🎉 수고하셨습니다.