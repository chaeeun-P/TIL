# ML 1주차 정규과제

📌ML 정규과제는 매주 정해진 **유튜브 강의 영상을 통해 머신러닝 이론을 학습**한 후, 해당 내용을 바탕으로 **실습 문제를 풀어보며 이해도를 높이는 학습 방식**입니다. 

이번주는 아래의 **ML_1st_TIL**에 명시된 유튜브 강의를 먼저 수강해 주세요. 학습 중에는 주요 개념을 스스로 정리하고, 이해가 어려운 부분은 강의 자료나 추가 자료를 참고해 보완해주세요. 과제까지 다 작성한 이후에 Github를 과제 시트에 제출해주시면 됩니다.



**(수행 인증샷은 필수입니다.)** 

> 주어진 과제를 다 한 이후, 인증샷이나 따로 코드를 깃허브에 정리하여 제출해주세요.



## ML_1st_TIL

### 수치예측, 범주예측

### 머신러닝 모델 학습 프로세스

### 선형회귀모델 1 (개요, 모델가정)

### 선형회귀모델 2 (파라미터 추정, 최소제곱법)

<br>

<!-- TIL에서 나와있는 강의 사이에 있는 과제에 해당이 되지 않는 강의도 내용이 연속적으로 진행하기 때문에 수강하시면 이해하기 쉬우실 것입니다. -->



## 주차별 학습 (Study Schedule)

| 주차   | 공부 범위                              | 완료 여부 |
| ------ | -------------------------------------- | --------- |
| 1주차. | 선형 회귀 (Linear Regression) (1)      | ✅         |
| 2주차  | 선형 회귀 (Linear Regression) (2)      | 🍽️         |
| 3주차  | 로지스틱 회귀 (Logistic Regression)    | 🍽️         |
| 4주차  | 결정 트리 (Decision Tree)              | 🍽️         |
| 5주차  | 앙상블 : 랜덤 포레스트 (Random Forest) | 🍽️         |
| 6주차  | 주성분 분석 (PCA)                      | 🍽️         |
| 7주차  | K - 평균 군집화                        | 🍽️         |

<!-- 여기까진 그대로 둬 주세요-->



---

# 1️⃣ 개념 정리

<!--“과제 내용 중 LaTeX 수식처럼 Git에 직접 정리하기 어려운 부분은 아이패드나 종이에 손으로 작성한 뒤 파일(이미지/PDF 등)로 첨부하여 인증해도 됩니다.” -->

## 01. 수치해석, 범주예측

```
✅ 학습 목표 :
* 수치예측과 범주예측의 차이를 이해할 수 있다.
* 다변량 데이터의 개념을 이해할 수 있다. 
* 예측 모델링의 목적을 강의에서 제시한 예시를 통해서 파악할 수 있다. 
```

### 수치예측과 범주예측의 차이
* 예측하려는 종속변수의 데이터 유형에 따라 모델링 방식이 구분됩니다.
* 수치 예측 (회귀): 연속형 변수(numerical, continuous)의 값을 예측하는 방식입니다. 예를 들어, 미래의 주가나 매출액을 예측하는 것이 이에 해당합니다.
* 범주 예측 (분류): 범주형 변수(categorical)의 라벨을 예측하는 방식입니다. 어떤 이메일이 스팸인지 아닌지를 분류하거나, 고객의 이탈 여부를 예측하는 것이 여기에 속합니다.

### 예측 모델링의 목적
* 예측 모델링은 단순히 값을 예측하는 것을 넘어, 다양한 비즈니스 목표를 달성하기 위해 활용됩니다.
* 값/라벨 예측: 미지의 값을 추정하는 가장 기본적인 목적입니다. 수치형 데이터에서는 매출이나 가격을 예측하고, 범주형 데이터에서는 스팸/정상 이메일 분류와 같은 문제에 적용됩니다.
* 의사결정 자동화: 예측 결과를 바탕으로 특정 행동을 자동화합니다. 예를 들어, 보험 사기가 의심되는 경우 자동으로 차단 플래그를 설정하거나, 이메일을 자동으로 분류하여 필요한 조치를 취하게 합니다.
* 개인화 및 타겟팅: 사용자별 특성에 맞는 맞춤형 추천이나 오퍼를 제공하는 데 사용됩니다. 이탈 가능성이 높은 고객에게 자동으로 할인 쿠폰을 발송하는 것이 좋은 예시입니다.



## 02. 머신러닝 모델 학습 프로세스

```
✅ 학습 목표 :
* 다변량 데이터에서 X와 Y의 관계를 이해할 수 있다.
* 머신러닝 모델이 파라미터(w1,w2 등)를 찾는 과정임을 이해할 수 있다.
* 비용함수 최소화를 통해 파라미터를 추정하는 원리를 이해할 수 있다. 
```

### 머신러닝 모델의 핵심 원리

머신러닝은 데이터에 숨겨진 패턴을 찾아 예측 모델을 구축하는 과정이다. 이 과정은 **X와 Y의 관계를 정의**하고, **최적의 파라미터를 찾아내어** 모델의 성능을 극대화하는 것을 목표로 한다.

---

### X와 Y의 관계 찾기

머신러닝의 가장 기본적인 목표는 **X와 Y의 관계**를 파악하는 것이다. 여기서 $Y$는 우리가 예측하고자 하는 대상(종속변수)이고, $X$는 $Y$를 설명하는 여러 독립변수들의 집합이다. 이들 변수 간의 관계는 선형적일 수도, 비선형적일 수도 있으며, 그 조합 방법은 무수히 많다. 머신러닝 학습 프로세스는 주어진 X와 Y 데이터로부터 가장 적절한 함수 $f(x)$를 찾아내는 과정이다.

---

### 파라미터 학습 과정

모델이 예측값을 만들어내기 위해서는 **파라미터**가 필요하다. 파라미터는 모델의 형태를 결정하는 핵심적인 숫자들로, 선형 회귀의 기울기와 절편($w_1, w_2, b$)이나 신경망의 가중치와 편향($w, b$)이 여기에 해당된다.

**학습(Training)**은 이 파라미터들을 데이터에 가장 잘 맞도록 최적화하는 과정이다. 이 과정은 다음과 같은 단계로 이루어진다.
1. **예측**: 모델에 데이터를 입력하여 예측값을 계산한다.
2. **오차 계산**: 예측값과 실제 값($Y$) 사이의 오차를 계산한다.
3. **파라미터 조정**: 오차를 줄이기 위해 파라미터를 업데이트한다. 이 과정은 여러 번 반복된다.

여기서 **하이퍼파라미터**(예: 학습률, 트리 깊이)는 사용자가 직접 설정하는 값인 반면, **파라미터**는 학습 과정을 통해 데이터로부터 자동으로 결정된다.

---

### 비용 함수 최소화 원리

머신러닝 모델 학습의 궁극적인 목표는 **비용 함수($J(w)$)**를 최소화하는 것이다. 비용 함수는 모델의 예측이 얼마나 잘못되었는지를 수치로 나타내는 지표이다.
* **회귀** 문제에서는 예측값과 실제 값의 차이를 제곱하여 평균을 낸 **평균 제곱 오차(MSE)**를 주로 사용한다.
* **분류** 문제에서는 **크로스 엔트로피(Cross-Entropy)**를 사용해 예측 확률 분포와 실제 라벨의 차이를 측정한다.

비용 함수를 최소화하기 위해 가장 널리 사용되는 방법은 **경사 하강법(Gradient Descent)**이다. 이 알고리즘은 비용 함수의 기울기($\nabla J$)를 계산하여, 기울기가 가리키는 반대 방향으로 파라미터를 조금씩 갱신한다. 파라미터 업데이트 공식은 $w \leftarrow w - \eta \cdot \nabla J(w)$이며, $\eta$(에타)는 **학습률**로, 파라미터가 얼마나 빠르게 갱신될지를 결정한다.

이러한 반복적인 최적화 과정은 비용 함수 값이 더 이상 줄어들지 않거나, 검증 데이터에서의 성능이 오히려 나빠질 때(조기 종료, Early Stopping) 멈추게 된다. 또한, **정규화(Regularization)** 기법을 사용하여 비용 함수에 페널티를 추가함으로써 모델의 복잡도를 줄여 과적합을 방지하고 더 일반화된 모델을 만들 수 있다.



## 03. 선형회귀모델 1 (개요, 모델 가정)

```
✅ 학습 목표 :
* 선형회귀모델의 개념과 목적을 이해할 수 있다.
* 확정적 관계와 확률적 관계의 차이를 이해할 수 있다.
* 선형회귀모델의 가정과 파라미터 추정의 의미를 이해할 수 있다. 
```

### 선형회귀모델의 개념과 목적

선형회귀모델(Linear Regression)은 독립변수(X)와 종속변수(Y) 사이의 **선형 관계를 추정하는 통계 모델**이다. 이 모델은 데이터의 패턴을 직선 형태의 방정식으로 표현한다. 직관적으로는, 데이터 포인트들 사이를 가장 잘 통과하는 최적의 직선을 찾는 과정이라고 이해할 수 있다.

**주요 목적**은 다음과 같다.
* X 변수가 Y 변수에 미치는 영향을 수치적으로 설명함.
* 주어진 X 변수들을 기반으로 미래의 Y 값을 예측함.

---

### 확정적 관계와 확률적 관계의 차이

변수 간의 관계는 오차항의 유무에 따라 두 가지로 구분된다.

* **확정적 관계**: $Y$를 $X$만으로 100% 표현할 수 있는 관계. 오차항이 존재하지 않는다.
* **확률적 관계**: $Y$를 $X$와 **오차항(확률오차)**으로 표현하는 관계. 현실 세계의 대부분 데이터는 측정 오류, 누락된 변수 등의 이유로 인해 이 확률적 관계를 따른다.

선형회귀모델은 이 확률적 관계를 기반으로 한다.

---

### 모델의 가정과 파라미터 추정

선형회귀모델은 $Y_i = \beta_0 + \beta_1X_i + \epsilon_i$ 와 같은 식으로 표현된다. 여기서 $\beta_0$와 $\beta_1$은 모델의 **파라미터(Parameter)**이며, $\epsilon_i$는 오차항(확률오차)이다.

**핵심**은 종속변수 $Y$를 독립변수 $X$들의 선형 결합으로 설명되는 부분과, 그렇지 않은 부분($\epsilon_i$)으로 나눈다는 점이다.

**오차항($\epsilon_i$)에 대한 주요 가정**
* **정규성**: 오차항은 정규분포를 따름.
* **등분산성**: 오차항들의 분산이 모두 동일함.
* **독립성**: 오차항들이 서로 독립적임.

모델 학습 과정은 주어진 데이터를 활용하여 오차를 최소화하는 **최적의 파라미터($\beta_0, \beta_1$)를 추정**하는 것을 의미한다.



## 04. 선형회귀모델 2 (파라미터 추정, 최소제곱법)

```
✅ 학습 목표 :
* 파라미터 추정의 목적과 과정(비용함수 최소화)을 이해할 수 있다.
* Least Square(최소제곱법)의 원리를 이해할 수 있다.
* 잔차(Residual)와 확률 오차(ε)의 차이를 구분할 수 있다. 
```

### 선형 회귀모델의 개념과 목적

선형 회귀모델(Linear Regression)은 독립변수(X)와 종속변수(Y) 사이의 **선형 관계를 추정하는 통계 모델**이다. 이 모델은 데이터의 패턴을 직선 형태의 방정식으로 표현한다. 직관적으로는, 데이터 포인트들 사이를 가장 잘 통과하는 최적의 직선을 찾는 과정이라고 이해할 수 있다.

**주요 목적**은 다음과 같다.
* X 변수가 Y 변수에 미치는 영향을 수치적으로 설명한다.
* 주어진 X 변수들을 기반으로 미래의 Y 값을 예측한다.

---

### 확정적 관계와 확률적 관계의 차이

변수 간의 관계는 오차항의 유무에 따라 두 가지로 구분된다.

**확정적 관계**는 $Y$를 $X$만으로 100% 표현할 수 있는 관계를 의미하며, 오차항이 존재하지 않는다. 반면, **확률적 관계**는 $Y$를 $X$와 **오차항(확률오차)**으로 표현하는 관계를 의미한다. 현실 세계의 대부분 데이터는 측정 오류, 누락된 변수 등의 이유로 인해 이 확률적 관계를 따른다. 선형 회귀모델은 이 확률적 관계를 기반으로 한다.

---

### 모델의 가정과 파라미터 추정

선형 회귀모델은 $Y_i = \beta_0 + \beta_1X_i + \epsilon_i$ 와 같은 식으로 표현된다. 여기서 $\beta_0$와 $\beta_1$은 모델의 **파라미터(Parameter)**이며, $\epsilon_i$는 오차항(확률오차)이다.

핵심은 종속변수 $Y$를 독립변수 $X$들의 선형 결합으로 설명되는 부분과, 그렇지 않은 부분($\epsilon_i$)으로 나눈다는 점이다.

**오차항($\epsilon_i$)에 대한 주요 가정**은 오차항이 정규분포를 따르며, 오차항들의 평균은 0이고 분산은 정규분포를 따른다는 것이다.

모델 학습 과정은 주어진 데이터를 활용하여 오차를 최소화하는 **최적의 파라미터($\beta_0, \beta_1$)를 추정**하는 것을 의미한다.


<br>
<br>

# 2️⃣ 과제

> **보스턴 주택 가격 데이터셋을 사용하여 주택 가격 예측 모델을 훈련 후, `model.coef_`값을 확인하고, 어떤 특성이 주택 가격에 가장 큰 부정적 / 부정적 영향을 미치는지 분석하여 설명하는 주피터 노트북을 작성하세요.** 

<!-- 주피터 노트북으로 작성한 경우, 깃허브에 해당 파일 링크를 올려 확인 가능하도록 권한을 설정하거나, 깃 레포지토리 내에 별도의 폴더를 만들어 함께 제출해도 됩니다. -->

~~~
과제 가이드
1. Boston Housing Dataset 소개
- sklearn.datasets.load_boston()으로 불러올 수 있는 데이터셋입니다. 
- 각 컬럼은 주택 가격에 영향을 줄 수 있는 다양한 특성을 나타냅니다. (예 : 평균 방 개수, 범죄율 등)

2. 선형회귀 모델 훈련
- sklearn.linear_model.LinearRegression( )을 사용해서 훈련할 수 있습니다.
- model.fit(X, y)를 사용하세요.

3. model.coef_ 해석 방법
- model.coef_ 는 각 특성(feature)의 계수(coefficient)를 의미합니다.
- 계수가 양수이면 그 특성이 클수록 주택 가격이 올라가는 것을 의미하고, 계수가 음수이면 그 특성이 클수록 주택 가격이 내려간다는 것을 의미합니다. 

4. 결과 분석 포인트
- model.coef_ 의 절댓값이 큰 변수가 가격에 더 큰 영향을 미칩니다. 
- 어떤 특성이 가장 긍정적인 영향을 미치고, 어떤 특성이 가장 부정적인 영향을 미치는지 찾아보세요.
- (X축 : 특성이름, Y축 : 계수 값) 을 사용하여 시각화를 사용해서 표현해도 좋습니다.

(참고) 깃허브 Machine-Learning Template 레포지토리의 base_code 폴더에 week1 과제를 수행하기 위한 기본 베이스 코드가 제공되니, 이를 참고해도 되고, 자유롭게 진행하셔도 됩니다.  
~~~



<br>

### 🎉 수고하셨습니다.