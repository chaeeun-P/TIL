# ML 3주차 정규과제

📌ML 정규과제는 매주 정해진 **유튜브 강의 영상을 통해 머신러닝 이론을 학습**한 후, 해당 내용을 바탕으로 **실습 문제를 풀어보며 이해도를 높이는 학습 방식**입니다. 

이번주는 아래의 **ML_3rd_TIL**에 명시된 유튜브 강의를 먼저 수강해 주세요. 학습 중에는 주요 개념을 스스로 정리하고, 이해가 어려운 부분은 강의 자료나 추가 자료를 참고해 보완해주세요. 과제까지 다 작성한 이후에 Github를 과제 시트에 제출해주시면 됩니다.



**(수행 인증샷은 필수입니다.)** 

> 주어진 과제를 다 한 이후, 인증샷이나 따로 코드를 깃허브에 정리하여 제출해주세요.



## ML_3rd_TIL

### 로지스틱 회귀모델 1 (로지스틱 함수, 승산)

### 로지스틱 회귀모델 2 (파라미터 추정, 해석)

<br>



## 주차별 학습 (Study Schedule)

| 주차   | 공부 범위                              | 완료 여부 |
| ------ | -------------------------------------- | --------- |
| 1주차. | 선형 회귀 (Linear Regression) (1)      | ✅         |
| 2주차  | 선형 회귀 (Linear Regression) (2)      | ✅         |
| 3주차  | 로지스틱 회귀 (Logistic Regression)    | ✅         |
| 4주차  | 결정 트리 (Decision Tree)              | 🍽️         |
| 5주차  | 앙상블 : 랜덤 포레스트 (Random Forest) | 🍽️         |
| 6주차  | 주성분 분석 (PCA)                      | 🍽️         |
| 7주차  | K - 평균 군집화                        | 🍽️         |

<!-- 여기까진 그대로 둬 주세요-->



---

# 1️⃣ 개념 정리

## 01. 로지스틱 회귀모델 1 (로지스틱 함수, 승산)

```
✅ 학습 목표 :
* 로지스틱 회귀모델이 필요한 이유와 적용 상황을 이해할 수 있다.
* 로지스틱 함수(시그모이드 함수)의 특징과 역할을 설명할 수 있다.
* Odds(승산)의 개념과 로짓 변환을 통해 선형 모델로 바꾸는 원리를 이해할 수 있다. 
```

### 📈 로지스틱 회귀 모델 (Logistic Regression Model)

---

### 1. 로지스틱 회귀 모델이 필요한 이유와 적용 상황

* **배경**: 기존의 선형 회귀 모델은 종속 변수(Y)가 **연속형 데이터**일 때 사용됩니다. 하지만 실제 데이터에서는 종속 변수가 **범주형(categorical)**인 경우가 많습니다. 예를 들어, 질병의 유무 (0 또는 1), 제품의 불량 여부 (양품 또는 불량), 고객의 이탈 여부 (이탈 또는 잔류)와 같은 경우.
* **문제점**: 종속 변수가 0 또는 1과 같은 이진 변수인 경우, 선형 회귀 모델을 적용하면 몇 가지 문제점이 발생.
    * **정규분포 가정 위배**: 오차(error)가 정규분포를 따른다는 선형 회귀 모델의 기본 가정이 깨집니다. Y가 0 또는 1 두 값만 가지므로 오차도 특정 값들만 가질 수 있어 정규분포를 따를 수 없음.
    * **분산 가정 위배**: 오차의 분산이 일정해야 한다는 가정이 위배.
    * **예측값 범위**: 선형 회귀 모델은 예측값이 음수나 1보다 큰 값을 가질 수 있지만, 0과 1 사이의 확률을 예측해야 하는 범주형 데이터에는 부적합.
* **해결**: 이러한 문제를 해결하고 범주형 종속 변수를 예측하기 위해 **로지스틱 회귀 모델**이 필요. 이 모델은 기본적으로 **분류(classification)** 문제를 해결하는 데 사용되며, 특정 범주에 속할 **확률**을 예측.

---

### 2. 로지스틱 함수(시그모이드 함수)의 특징과 역할

* **로지스틱 함수 형태**: 로지스틱 회귀 모델은 선형 결합을 **로지스틱 함수(Logistic Function)** 또는 **시그모이드 함수(Sigmoid Function)**에 통과시켜 0과 1 사이의 값을 가지도록 변환. 
* **로지스틱 함수**: $p(x) = \frac{1}{1 + e^{-(b_0 + b_1x)}}$
* **특징**:
    * **S자 커브(S-curve)**: 로지스틱 함수의 그래프는 S자 형태를 띠며, 특정 구간에서 기울기가 가파르게 증가하는 특징을 보임.
    * **입력과 출력**: 입력값($x$)은 $-\infty$에서 $+\infty$까지 모든 실수가 가능하지만, 출력값(Y)은 항상 **0과 1 사이**의 값을 가짐. 이는 특정 사건이 발생할 **확률**을 나타내는 데 매우 적합.
    * **스쿼싱(Squashing) 함수**: 입력값을 0과 1 사이로 압축(squash)하는 역할을 하므로 'Squashing Function'이라고도 불림.

* **역할**: 로지스틱 함수는 선형 회귀 모델의 결과($b_0 + b_1x$)를 **확률**로 해석할 수 있도록 변환하는 핵심적인 역할을 함. 이를 통해 $x$가 주어졌을 때 $Y$가 특정 범주(예: 1)에 속할 확률을 예측할 수 있음.

---

### 3. Odds(승산)의 개념과 로짓 변환

* **Odds(승산)의 개념**: 성공 확률(p)과 실패 확률(1-p)의 **비율**을 의미.
    * $Odds = \frac{p}{1-p}$
    * **특징**: Odds의 값은 0부터 무한대까지의 범위를 가집니다. 확률 p가 1에 가까울수록 Odds는 무한대에 가까워지고, p가 0에 가까울수록 Odds는 0에 가까워짐.

* **로짓 변환(Logit Transformation)**: Odds에 자연로그($\ln$)를 취하여 선형 모델 형태로 변환하는 과정.
    * $Logit = \ln(\frac{p}{1-p})$
* **로짓 변환의 효과**: 로지스틱 함수를 로짓 변환하면 복잡한 비선형 관계가 단순한 선형 관계로 바뀜.
    * $\ln(\frac{p}{1-p}) = b_0 + b_1x$
* **로짓 변환의 중요성**:
    * **선형성 확보**: 확률($p$)은 0과 1 사이의 비선형 관계를 가지지만, 로짓 변환을 통해 Odds의 로그값은 $x$와 **선형적인 관계**를 갖게 됨. 이를 통해 선형 회귀의 예측 방식과 유사하게 모델 파라미터($b_0, b_1$)를 해석할 수 있게 됨.
    * **파라미터 해석 용이**: $b_1$은 $x$가 1단위 증가할 때, Odds의 로그값이 증가하는 양을 의미함. 이는 Odds 자체를 직접 해석하는 것보다 훨씬 직관적임.



## 02. 로지스틱 회귀모델 2 (파라미터 추정, 해석)

```
✅ 학습 목표 :
* 로지스틱 회귀모델에서 파라미터를 추정하는 원리를 이해할 수 있다.
* 최대우도추정법(MLE)의 필요성과 동작 원리를 이해할 수 있다.
* 로지스틱 회귀모델의 회귀계수 해석 방법을 이해할 수 있다. 
```

### 1. 로지스틱 회귀 모델에서 파라미터를 추정하는 원리

* **파라미터 추정의 목표**: 로지스틱 회귀 모델에서 파라미터($\beta_0, \beta_1, ...$)를 추정하는 것은 주어진 데이터를 가장 잘 설명하는 모델을 찾는 것임. 이 '가장 잘 설명하는 모델'은 예측한 확률이 실제 관측된 결과(0 또는 1)와 가장 유사하도록 하는 파라미터를 의미함.
* **추정 방식의 차이**: 선형 회귀 모델은 **최소제곱법(Least Squares)**을 통해 파라미터를 추정함. 이는 예측값과 실제값의 오차 제곱합을 최소화하는 방식임. 하지만 로지스틱 회귀 모델의 종속 변수는 0 또는 1이므로, 오차 제곱합을 최소화하는 방식은 적합하지 않음.
* **해결**: 로지스틱 회귀 모델은 **최대우도추정법(Maximum Likelihood Estimation, MLE)**을 사용하여 파라미터를 추정함.

---

### 2. 최대우도추정법(MLE)의 필요성과 동작 원리

* **최대우도추정법(MLE)이란**: 주어진 데이터가 특정 확률분포(여기서는 베르누이 분포)에서 나왔을 가능성(우도, Likelihood)을 최대로 만드는 파라미터를 찾는 통계적 방법임.
* **동작 원리**:
    1.  **우도 함수(Likelihood Function) 정의**: 각 데이터 포인트에 대해 예측된 확률($p$)과 실제값(y)의 곱으로 우도 함수를 정의함. $L(\beta) = \prod_{i=1}^n p_i^{y_i} (1-p_i)^{1-y_i}$. 여기서 $\prod$는 모든 관측치에 대한 곱셈을 의미함.
    2.  **로그 우도 함수(Log-Likelihood Function) 변환**: 우도 함수는 곱셈 형태로 되어 있어 다루기 어렵기 때문에, 로그를 취하여 덧셈 형태로 변환함. $\ln(L(\beta))$. 이 로그 우도 함수를 최대로 만드는 $\beta$ 값을 찾는 것이 목표임.
    3.  **수치 최적화**: 로그 우도 함수는 $\beta$에 대해 비선형이므로, 미분해서 해를 찾는 명시적인 해(closed-form solution)가 존재하지 않음. 따라서 **경사 하강법(Gradient Descent)**과 같은 **수치 최적화 알고리즘**을 사용하여 로그 우도 함수를 최대화하는 $\beta$ 값을 반복적으로 찾아나감.
* **크로스 엔트로피(Cross-Entropy)와의 관계**: 로그 우도 함수를 최대화하는 것은 **크로스 엔트로피**를 최소화하는 것과 동일한 의미임. 크로스 엔트로피는 두 확률분포(예: 실제 데이터의 분포와 모델이 예측한 분포) 간의 차이를 측정하는 척도로 사용됨.

---

### 3. 로지스틱 회귀 모델의 회귀계수 해석 방법

* **로짓 변환을 통한 해석**: 로지스틱 회귀 모델의 회귀계수($\beta$)는 선형 회귀처럼 직접적으로 해석하기 어려움. 그러나 **로짓 변환**을 통해 회귀계수를 **로그 Odds(Log-Odds)**의 변화량으로 해석할 수 있음.
    * $x$가 1단위 증가할 때, **로그 Odds**는 $\beta$만큼 증가함.

* **승산비(Odds Ratio)를 통한 해석**: 로지스틱 회귀 모델의 결과를 가장 직관적으로 이해할 수 있는 방법임. Odds Ratio는 $e^\beta$로 계산됨.
    * **Odds Ratio > 1**: 회귀계수($\beta$)가 양수일 때, Odds Ratio는 1보다 큼. 이는 해당 변수가 1단위 증가할 때 **성공 확률(Odds)**이 증가한다는 것을 의미함. 예를 들어, Odds Ratio가 1.03이면, 해당 변수가 1단위 증가할 때 성공 확률은 3% 증가함.
    * **Odds Ratio < 1**: 회귀계수($\beta$)가 음수일 때, Odds Ratio는 0과 1 사이의 값을 가짐. 이는 해당 변수가 1단위 증가할 때 **성공 확률**이 감소한다는 것을 의미함. 예를 들어, Odds Ratio가 0.38이면, 해당 변수가 1단위 증가할 때 성공 확률은 약 62% 감소함.
* **최종 분류**: 모델이 예측한 확률 값(0~1)은 일반적으로 **임계값(threshold)**을 기준으로 분류됨.
    * **기본 임계값**: 일반적으로 0.5를 기준으로 함. 확률이 0.5보다 크면 범주 1로, 작으면 범주 0으로 분류함.
    * **임계값 조정**: 예측의 목적에 따라 임계값을 조정할 수 있음. 예를 들어, 불량품 예측이나 질병 진단과 같이 보수적인 예측이 필요할 때는 임계값을 낮추어(예: 0.2) '불량' 또는 '질병'으로 분류될 확률을 높일 수 있음.



<br>
<br>

---

# 2️⃣ 과제

> **유방암 진단 데이터를 사용하여 악성 종양 여부를 예측하는 모델을 만들어 봅시다. 혼동 행렬(Confusion Matrix)을 출력하고, 이 문제에서 '재현율(Recall)'이 왜 중요한 평가지표가 되는지 자신의 생각을 정리하여 주피터 노트북에 작성하세요.**



~~~
과제 가이드
1. 데이터 불러오기
- from sklearn.datasets import load_breast_cancer
- X, y로 데이터를 분리하세요.

2. 모델 훈련
- from sklearn.linear_model import LogisticRegression
- model.fit(X_train, y_train)으로 학습

3. 예측 및 평가
- model.predict(X_test)를 통해 에측이 가능합니다.
- 평가시에 from sklearn.metrics import confusion_matrix, classification_report를 사용하시면 더 편하게 하실 수 있습니다. 

* 혼동 행렬 (Confusion Matrix) 해석
- True Positive (TP) : 실제 악성 + 예측 악성
- False Negative (FN) : 실제 악성 + 예측 양성 (위험되는 부분)
- Recall (재현율) : TP / (TP + FN) 
	'실제 악성'인 것중에서 우리가 잘 맞춘 비율 
	
(참고) 깃허브 Machine-Learning Template 레포지토리의 base_code 폴더에 week2 과제를 수행하기 위한 기본 베이스 코드가 제공되니, 이를 참고해도 되고, 자유롭게 진행하셔도 됩니다. 
~~~



<br>

### 🎉 수고하셨습니다.